{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод главных компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм PCA\n",
    "\n",
    "Дана матрица данных $D$ и коэффициент $\\alpha$:\n",
    "1. вычисляем среднее значение $\\mu = \\frac{1}{n} \\sum \\limits_{i=1}^{n} x_i$;\n",
    "2. центруем матрицу данных $Z = D - 1 \\cdot \\mu^T$;\n",
    "3. вычисляем матрицу ковариаций $K = \\frac{1}{n} (Z^T Z)$;\n",
    "4. вычисляем собственные значения $(\\lambda_1, \\lambda_2, \\ldots, \\lambda_d)$;\n",
    "5. вычисляем собственные векторы $U = (u_1 u_2 \\ldots u_d)$;\n",
    "6. вычисляем долю общей дисперсии $f(r) = \\frac{\\sum_{i=1}^{r} \\lambda_i} {\\sum_{i=1}^{n} \\lambda_i}$;\n",
    "7. выбираем наименьший $r$ так, чтобы $f(r) \\geq \\alpha$;\n",
    "8. выбираем $r$ первых векторов $U = (u_1 u_2 \\ldots u_r)$;\n",
    "9. уменьшаем признаковое пространство: $A = \\{ a_i \\: | \\: a_i = U_r^T x_i, \\: для \\: i = 1, \\ldots, n \\} $\n",
    "\n",
    "Реализуйте алгоритм для первых двух главных компонент. Найдите $\\lambda_1$, $\\lambda_2$ и $u_1$, $u_2$. Спроецируйте данные на плоскость образуемую этими векторами, визуализируйте полученные результаты c метками классов. Сравните реузльтаты с методом PCA из библиотеки sklearn.decomposition.\n",
    "\n",
    "В качестве данных возьмите изображения с рукописными цифрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "%matplotlib inline\n",
    "\n",
    "data = load_iris()\n",
    "x, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе полученных собственных значений ковариационной матриы $K$ постройте график зависимости покрываемой дисперсии трансформированных данных от количества главных компонент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интерпретация компонент\n",
    "## Корреляция с исходными признаками\n",
    "Главные компоненты являются линейными кобинациями исходных признаков. В этой связи необходимо оценить связь каждой компоненты с исходными признаками.\n",
    "\n",
    "Рассчет взаимосвязи будем проводить с помощью корреляции Пирсона:\n",
    "\n",
    "\\begin{equation}\n",
    "r_{jk} = \\frac{\\sum_{i=1}^n (x_{ij} - \\bar{x}_j) (x_{ik}' - \\bar{x}_k')}{\\sqrt{\\sum_{i=1}^n (x_{ij} - \\bar{x}_j)^2 \\sum_{i=1}^n (x_{ik}' - \\bar{x}_k')^2}}\n",
    "\\end{equation}\n",
    "\n",
    "где\n",
    "$\\bar{x}_j$ - среднее значение $j$-го признака,\n",
    "$\\bar{x}_k'$ - среднее значение проекции на $k$-ю главную компоненту,\n",
    "$n$ - количество объектов.\n",
    "\n",
    "Отметим, что корреляция Пирсона изменяется от $-1$ до $+1$. Она равна $0$ в случае, когда величины независимы, и $\\pm 1$, если они линейно зависимы.\n",
    "\n",
    "Определите по коэффициентам корреляции, какие признаки в какую компоненту вошли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
